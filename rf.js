// ========================================================================
// FLOOD RISK PREDICTION MODEL USING RANDOM FOREST REGRESSION
// B√†i to√°n: H·ªíI QUY - D·ª± ƒëo√°n x√°c su·∫•t li√™n t·ª•c t·ª´ 0-1
// Lu·ªìng: Load Assets ‚Üí Extract Features ‚Üí Train Model ‚Üí Predict
// ========================================================================

// C·∫§U H√åNH M√î H√åNH
var RESOLUTION = 30;  // 30m resolution
var NUM_TREES = 200;   // S·ªë c√¢y trong Random Forest
var TILE_SCALE = 16;  // TƒÉng t·ªëc x·ª≠ l√Ω
var TRAIN_SPLIT = 0.7; // 70% train, 30% validation

// T√™n 13 features t·ª´ imageAsset
var featureNames = [
  'lulc', 'Density_River', 'Density_Road', 'Distan2river', 'Distan2road_met',
  'aspect', 'curvature', 'dem', 'flowDir', 'slope', 'twi', 'NDVI', 'rainfall'
];

print('========== FLOOD RISK PREDICTION - RANDOM FOREST REGRESSION ==========');
print('Problem Type: REGRESSION (continuous probability 0-1)');
print('Resolution: ' + RESOLUTION + 'm');
print('Number of trees: ' + NUM_TREES);
print('Features: 13 bands from imageAsset');

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 1: LOAD 3 FILE ASSETS ƒê·∫¶U V√ÄO
//////////////////////////////////////////////////////////////

print('========== STEP 1: LOADING INPUT ASSETS ==========');

// 1.1 Load Study Area (SHP file)
if (typeof studyArea === 'undefined') {
  print('ERROR: studyArea ch∆∞a ƒë∆∞·ª£c import!');
  print('H∆∞·ªõng d·∫´n: Import SHP file t·ª´ Assets tab v√† ƒë·∫∑t t√™n l√† "studyArea"');
}
print('‚úÖ Study area loaded');

// 1.2 Load Image Features (13 bands)
if (typeof imageAsset === 'undefined') {
  print('ERROR: imageAsset ch∆∞a ƒë∆∞·ª£c import!');
  print('H∆∞·ªõng d·∫´n: Import Image asset (13 bands) v√† ƒë·∫∑t t√™n l√† "imageAsset"');
}
print('‚úÖ Image asset loaded');

// 1.3 Load Flood Points (CSV v·ªõi 3 c·ªôt: lat, lon, flood)
if (typeof floodPoints === 'undefined') {
  print('ERROR: floodPoints ch∆∞a ƒë∆∞·ª£c import!');
  print('H∆∞·ªõng d·∫´n: Import CSV file (lat, lon, flood) v√† ƒë·∫∑t t√™n l√† "floodPoints"');
}

// ƒê·∫£m b·∫£o geometry ƒë∆∞·ª£c t·∫°o ƒë√∫ng t·ª´ lon, lat
var floodPoints = floodPoints.map(function(feature) {
  var lon = ee.Number(feature.get('lon'));
  var lat = ee.Number(feature.get('lat'));
  // ƒê·∫£m b·∫£o flood value l√† s·ªë (0 ho·∫∑c 1)
  var floodValue = ee.Number(feature.get('flood'));
  return feature.set('flood', floodValue)
                .setGeometry(ee.Geometry.Point([lon, lat], 'EPSG:4326'));
});

print('‚úÖ Flood points loaded and geometries created');

// Ki·ªÉm tra c·∫•u tr√∫c flood points
var samplePoint = ee.Feature(floodPoints.first());
print('Sample flood point properties:', samplePoint.propertyNames());
print('Sample flood value:', samplePoint.get('flood'));
print('Total flood points:', floodPoints.size());

// ƒê·∫øm s·ªë ƒëi·ªÉm flood v√† non-flood
var floodCount = floodPoints.filter(ee.Filter.eq('flood', 1)).size();
var nonFloodCount = floodPoints.filter(ee.Filter.eq('flood', 0)).size();
print('Flood points (flood=1):', floodCount);
print('Non-flood points (flood=0):', nonFloodCount);

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 2: TR√çCH XU·∫§T 13 FEATURES T·∫†I C√ÅC ƒêI·ªÇM NH√ÉN
//////////////////////////////////////////////////////////////

print('========== STEP 2: EXTRACTING FEATURES AT LABELED POINTS ==========');

// 2.0 DEBUG: Ki·ªÉm tra band names
print('Expected feature names:', featureNames);
print('Actual band names in imageAsset:', imageAsset.bandNames());

// 2.1 Chu·∫©n b·ªã features t·ª´ imageAsset
var features = imageAsset.select(featureNames).clip(studyArea);

// Reproject v·ªõi scale mong mu·ªën
features = features.reproject({
  crs: 'EPSG:4326',
  scale: RESOLUTION
});

print('‚úÖ Features prepared with', featureNames.length, 'bands');

// 2.1.5 DEBUG: Test tr√™n 1 ƒëi·ªÉm c·ª• th·ªÉ
print('========== DEBUG: TESTING FIRST POINT ==========');
var firstPoint = ee.Feature(floodPoints.first());
print('First point properties:', firstPoint.toDictionary());

var testGeom = firstPoint.geometry();
print('Test geometry coordinates:', testGeom.coordinates());

// L·∫•y gi√° tr·ªã t·∫°i ƒëi·ªÉm n√†y
var pixelValues = features.reduceRegion({
  reducer: ee.Reducer.first(),
  geometry: testGeom,
  scale: RESOLUTION,
  maxPixels: 1e9
});
print('üéØ Pixel values at first point:', pixelValues);
print('üéØ Number of non-null values:', pixelValues.keys().length());

// 2.2 Sample features t·∫°i c√°c ƒëi·ªÉm flood
print('========== SAMPLING ALL POINTS ==========');

var trainingData = features.sampleRegions({
  collection: floodPoints,
  properties: ['flood', 'lat', 'lon'],
  scale: RESOLUTION,
  tileScale: TILE_SCALE,
  geometries: true  // Gi·ªØ geometry ƒë·ªÉ debug
});

print('Total points after sampling:', trainingData.size());

// DEBUG: Xem 3 ƒëi·ªÉm ƒë·∫ßu ti√™n sau khi sample
var firstThree = trainingData.limit(3);
print('First 3 sampled points (check for null values):', firstThree);

// Ki·ªÉm tra t·ª´ng feature xem feature n√†o b·ªã null
print('========== CHECKING NULL VALUES PER FEATURE ==========');
featureNames.forEach(function(bandName) {
  var countNonNull = trainingData.filter(ee.Filter.notNull([bandName])).size();
  print('  Feature "' + bandName + '" - Non-null points:', countNonNull);
});

// 2.3 L·ªçc b·ªè c√°c ƒëi·ªÉm thi·∫øu d·ªØ li·ªáu
var requiredColumns = ['flood'].concat(featureNames);
trainingData = trainingData.filter(ee.Filter.notNull(requiredColumns));

print('‚úÖ Valid training samples after filtering:', trainingData.size());

// N·∫øu kh√¥ng c√≥ training data, d·ª´ng l·∫°i v√† hi·ªÉn th·ªã visualization
var validSampleCount = trainingData.size();
validSampleCount.evaluate(function(count) {
  if (count === 0) {
    print('‚ùå ERROR: NO VALID TRAINING DATA!');
    print('Possible reasons:');
    print('  1. Band names mismatch - Check "Expected" vs "Actual" band names above');
    print('  2. Points outside imageAsset coverage - Check map visualization');
    print('  3. NoData values in imageAsset at point locations');
    print('');
    print('ACTION REQUIRED:');
    print('  ‚Üí Check the map to see if points overlap with image data');
    print('  ‚Üí Verify band names match exactly (case-sensitive)');
    print('  ‚Üí Check if imageAsset has valid data in study area');
  }
});

// 2.4 Chia d·ªØ li·ªáu train/validation
var withRandom = trainingData.randomColumn('random', 42);
var training = withRandom.filter(ee.Filter.lt('random', TRAIN_SPLIT));
var validation = withRandom.filter(ee.Filter.gte('random', TRAIN_SPLIT));

print('Training samples:', training.size());
print('Validation samples:', validation.size());

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 3: HU·∫§N LUY·ªÜN M√î H√åNH RANDOM FOREST REGRESSION
//////////////////////////////////////////////////////////////

print('========== STEP 3: TRAINING RANDOM FOREST REGRESSOR ==========');

// S·ª¨ D·ª§NG REGRESSOR THAY V√å CLASSIFIER
var rfRegressor = ee.Classifier.smileRandomForest({
  numberOfTrees: NUM_TREES,
  variablesPerSplit: null,      // sqrt(numFeatures) - t·ª± ƒë·ªông
  minLeafPopulation: 1,
  bagFraction: 0.5,
  seed: 42
}).setOutputMode('REGRESSION')  // QUAN TR·ªåNG: Ch·∫ø ƒë·ªô REGRESSION
  .train({
    features: training,
    classProperty: 'flood',  // D√π t√™n l√† classProperty nh∆∞ng ƒë√¢y l√† gi√° tr·ªã li√™n t·ª•c
    inputProperties: featureNames
  });

print('‚úÖ Random Forest Regressor trained successfully');
print('Model configuration:');
print('  - Mode: REGRESSION (continuous output)');
print('  - Trees:', NUM_TREES);
print('  - Input features:', featureNames.length);

// 3.1 ƒê√°nh gi√° tr√™n t·∫≠p validation
print('========== VALIDATION METRICS (REGRESSION) ==========');

var validationPredicted = validation.classify(rfRegressor, 'predicted');

// T√≠nh c√°c metrics cho regression
var validationMetrics = validationPredicted.select(['flood', 'predicted'])
  .reduceColumns({
    reducer: ee.Reducer.spearmansCorrelation().combine({
      reducer2: ee.Reducer.pearsonsCorrelation(),
      sharedInputs: true
    }),
    selectors: ['flood', 'predicted']
  });

print('Spearman Correlation:', validationMetrics.get('correlation'));
print('Pearson Correlation:', validationMetrics.get('correlation1'));

// T√≠nh RMSE v√† MAE
var errors = validationPredicted.map(function(f) {
  var observed = ee.Number(f.get('flood'));
  var predicted = ee.Number(f.get('predicted'));
  var error = observed.subtract(predicted);
  var squaredError = error.pow(2);
  var absError = error.abs();
  return f.set({
    'error': error,
    'squared_error': squaredError,
    'abs_error': absError
  });
});

var rmse = errors.aggregate_mean('squared_error');
var mae = errors.aggregate_mean('abs_error');

print('RMSE (Root Mean Squared Error):', rmse);
print('MAE (Mean Absolute Error):', mae);

// Feature importance
var importance = rfRegressor.explain();
print('Feature Importance:', importance);

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 4: TH·ª∞C HI·ªÜN PREDICT TR√äN TO√ÄN B·ªò KHU V·ª∞C
//////////////////////////////////////////////////////////////

print('========== STEP 4: MAKING PREDICTIONS (REGRESSION) ==========');

// 4.1 Predict flood probability (li√™n t·ª•c 0-1) cho to√†n b·ªô khu v·ª±c
var floodProbability = features.classify(rfRegressor).rename('flood_probability');

// ƒê·∫£m b·∫£o gi√° tr·ªã trong kho·∫£ng [0, 1]
floodProbability = floodProbability.clamp(0, 1);

// 4.2 T·∫°o b·∫£n ƒë·ªì ph√¢n lo·∫°i d·ª±a tr√™n ng∆∞·ª°ng (optional)
var THRESHOLD = 0.5;  // Ng∆∞·ª°ng ph√¢n lo·∫°i: >= 0.5 l√† flood
var floodClassification = floodProbability.gte(THRESHOLD).rename('flood_class');

// 4.3 T·∫°o b·∫£n ƒë·ªì risk levels
var riskLevels = floodProbability
  .where(floodProbability.lt(0.25), 1)  // Low risk
  .where(floodProbability.gte(0.25).and(floodProbability.lt(0.5)), 2)  // Moderate
  .where(floodProbability.gte(0.5).and(floodProbability.lt(0.75)), 3)  // High
  .where(floodProbability.gte(0.75), 4)  // Very High
  .rename('risk_level');

// 4.4 Reproject k·∫øt qu·∫£
floodProbability = floodProbability.reproject({
  crs: 'EPSG:4326',
  scale: RESOLUTION
}).clip(studyArea);

floodClassification = floodClassification.reproject({
  crs: 'EPSG:4326',
  scale: RESOLUTION
}).clip(studyArea);

riskLevels = riskLevels.reproject({
  crs: 'EPSG:4326',
  scale: RESOLUTION
}).clip(studyArea);

print('‚úÖ Prediction completed');
print('Output range check - Min/Max probability:');
var stats = floodProbability.reduceRegion({
  reducer: ee.Reducer.minMax(),
  geometry: studyArea,
  scale: RESOLUTION * 10,  // Coarser scale for speed
  maxPixels: 1e9
});
print('  Min probability:', stats.get('flood_probability_min'));
print('  Max probability:', stats.get('flood_probability_max'));

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 5: HI·ªÇN TH·ªä K·∫æT QU·∫¢
//////////////////////////////////////////////////////////////

print('========== STEP 5: DISPLAYING RESULTS ==========');

// Hi·ªÉn th·ªã b·∫£n ƒë·ªì
Map.centerObject(studyArea, 10);

// Hi·ªÉn th·ªã khu v·ª±c nghi√™n c·ª©u
Map.addLayer(studyArea, {color: '0000FF'}, 'Study Area Boundary', true, 0.3);

// Hi·ªÉn th·ªã imageAsset ƒë·ªÉ ki·ªÉm tra coverage
Map.addLayer(imageAsset.select(0), {min: 0, max: 1000}, 'Image Asset (First Band)', false);

// Hi·ªÉn th·ªã c√°c ƒëi·ªÉm training
var floodPts = floodPoints.filter(ee.Filter.eq('flood', 1));
var nonFloodPts = floodPoints.filter(ee.Filter.eq('flood', 0));
Map.addLayer(floodPts, {color: 'FF0000'}, 'Flood Points (1)', true);
Map.addLayer(nonFloodPts, {color: '00FF00'}, 'Non-Flood Points (0)', true);

// Hi·ªÉn th·ªã k·∫øt qu·∫£ REGRESSION - Continuous Probability (0-1)
var probPalette = {
  min: 0,
  max: 1,
  palette: ['#00FF00', '#FFFF00', '#FF9900', '#FF0000']  // Green ‚Üí Yellow ‚Üí Orange ‚Üí Red
};
Map.addLayer(floodProbability, probPalette, 'üéØ Flood Probability (Continuous 0-1)', true);

// Hi·ªÉn th·ªã classification v·ªõi ng∆∞·ª°ng (optional)
var classPalette = {
  min: 0,
  max: 1,
  palette: ['green', 'red']
};
Map.addLayer(floodClassification, classPalette, 'Flood Classification (Threshold=0.5)', false);

// Hi·ªÉn th·ªã risk levels
var riskPalette = {
  min: 1,
  max: 4,
  palette: ['#00FF00', '#FFFF00', '#FF9900', '#FF0000']
};
Map.addLayer(riskLevels, riskPalette, 'Risk Levels (Low/Mod/High/VeryHigh)', false);

// Th√™m legend
var legend = ui.Panel({
  style: {
    position: 'bottom-left',
    padding: '8px 15px'
  }
});

var legendTitle = ui.Label({
  value: 'Flood Probability',
  style: {fontWeight: 'bold', fontSize: '16px', margin: '0 0 4px 0'}
});
legend.add(legendTitle);

var makeRow = function(color, name) {
  var colorBox = ui.Label({
    style: {
      backgroundColor: color,
      padding: '8px',
      margin: '0 0 4px 0'
    }
  });
  var description = ui.Label({
    value: name,
    style: {margin: '0 0 4px 6px'}
  });
  return ui.Panel({
    widgets: [colorBox, description],
    layout: ui.Panel.Layout.Flow('horizontal')
  });
};

legend.add(makeRow('#00FF00', '0.00 - 0.25: Low Risk'));
legend.add(makeRow('#FFFF00', '0.25 - 0.50: Moderate Risk'));
legend.add(makeRow('#FF9900', '0.50 - 0.75: High Risk'));
legend.add(makeRow('#FF0000', '0.75 - 1.00: Very High Risk'));

Map.add(legend);

print('‚úÖ Map layers added - Check visualization');

//////////////////////////////////////////////////////////////
// B∆Ø·ªöC 6: EXPORT K·∫æT QU·∫¢
//////////////////////////////////////////////////////////////

print('========== STEP 6: EXPORTING RESULTS ==========');

// Export flood probability map (CONTINUOUS 0-1)
Export.image.toDrive({
  image: floodProbability,
  description: 'flood_probability_RF_regression',
  scale: RESOLUTION,
  region: studyArea,
  maxPixels: 1e13,
  fileFormat: 'GeoTIFF'
});

// Export flood classification map (binary with threshold)
Export.image.toDrive({
  image: floodClassification,
  description: 'flood_classification_RF_threshold',
  scale: RESOLUTION,
  region: studyArea,
  maxPixels: 1e13,
  fileFormat: 'GeoTIFF'
});

// Export risk levels map
Export.image.toDrive({
  image: riskLevels,
  description: 'flood_risk_levels_RF',
  scale: RESOLUTION,
  region: studyArea,
  maxPixels: 1e13,
  fileFormat: 'GeoTIFF'
});

// Export validation results v·ªõi predicted values
Export.table.toDrive({
  collection: validationPredicted.select(['lat', 'lon', 'flood', 'predicted', 'error', 'squared_error', 'abs_error']),
  description: 'validation_results_RF_regression',
  fileFormat: 'CSV'
});

print('========== PROCESS COMPLETED ==========');
print('‚úÖ Check Tasks tab to run exports');
print('');
print('üìä REGRESSION OUTPUTS:');
print('  1. Flood Probability Map (continuous 0-1)');
print('  2. Flood Classification Map (binary with threshold=0.5)');
print('  3. Risk Levels Map (4 categories)');
print('  4. Validation Results CSV (with predicted values)');
print('');
print('‚ö†Ô∏è If you see "No valid training data" error:');
print('  1. Check console logs above for band name mismatches');
print('  2. Verify points overlap with image data on map');
print('  3. Ensure imageAsset has valid data (not all NoData)');